{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generates reconstructions of the smoothed PSTH  from the PC responses for each trail for the single units. \n",
    "\n",
    "#### Run this notebook after GenerateDataBase2\n",
    "\n",
    "#### You should only have to modify the rootPath in cell 2 for this notebook to work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies \n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "from scipy.stats import t\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Paths\n",
    "Note that it is assumed that you have data directory accessible from the rootPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootPath = '/Users/frederictheunissen/Google Drive/My Drive/julie/'\n",
    "pklPath = 'pkl'\n",
    "\n",
    "\n",
    "# The 6 birds from Julie data set\n",
    "birds = ['BlaBro09xxF', 'GreBlu9508M', 'WhiBlu5396M', 'LblBlu2028M', 'WhiWhi4522M', 'YelBlu6903F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data base\n",
    "# Temp save of results\n",
    "inPath = rootPath+'JulieDataBase.pkl'\n",
    "fileIn = open(inPath,\"rb\")\n",
    "dfDataBase = pk.load(fileIn)\n",
    "pcKDE = pk.load(fileIn)\n",
    "fileIn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDataBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCs of KDE\n",
    "print(pcKDE.explained_variance_ratio_)\n",
    "\n",
    "fig = plt.figure(figsize=(8,4), dpi = 300)\n",
    "\n",
    "plt.plot(np.linspace(1,10, num=10), np.cumsum(pcKDE.explained_variance_ratio_))\n",
    "plt.xlabel('Number of PCs')\n",
    "plt.ylabel('Variance Explained')\n",
    "\n",
    "plt.savefig('/Users/frederictheunissen/Desktop/PCAVarianceExplainedJulie.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(8,4), dpi=300)\n",
    "plt.plot(pcKDE.mean_*.005, label='Mean')\n",
    "plt.plot(pcKDE.components_[0,:], label='PC0')\n",
    "plt.plot(pcKDE.components_[1,:], label='PC1')\n",
    "plt.plot(pcKDE.components_[2,:], label='PC2')\n",
    "plt.plot(pcKDE.components_[3,:], label='PC3')\n",
    "plt.plot(pcKDE.components_[4,:], label='PC4')\n",
    "plt.xlabel('Time (ms)')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('/Users/frederictheunissen/Desktop/PCA5PCsJulie.eps')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "These are the same functions that are in GenerateDataBase2 and are needed to select the auditory units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These 3 z_score_stim functions could be combinned into 1.\n",
    "\n",
    "def calc_zscore_stim(stimName):\n",
    "    global dfRelTime\n",
    "    \n",
    "    rows = []\n",
    "    # This loop finds all rows that match but there should only be one.\n",
    "    for index, row in dfRelTime.iterrows():\n",
    "        if row['file'] == stimName:\n",
    "            rows.append(row)\n",
    "    if (len(rows) != 1):\n",
    "        print('Stimulus not found or too many')\n",
    "        return 0.0, 1.0, 0\n",
    "    \n",
    "    # Choose one and only\n",
    "    row = rows[0]\n",
    "    \n",
    "    # Calculates response diff for each stim\n",
    "    spikeDiff = np.zeros(row['nTrials'])\n",
    "    for it in range(row['nTrials']):\n",
    "        spikeDiff[it] = np.sum((row['spikeTimes'][it] >= 0) & (row['spikeTimes'][it] < 0.5)) - np.sum((row['spikeTimes'][it] >= -0.5) & (row['spikeTimes'][it] < 0)) \n",
    "           \n",
    "    # Calculate z-score and pvalue\n",
    "    if (row['nTrials'] > 1) :\n",
    "        sdiffSD = np.std(spikeDiff, ddof=1)\n",
    "        if sdiffSD == 0:\n",
    "            spikeDiff[0] += 1\n",
    "            sdiffSD = np.std(spikeDiff, ddof=1)\n",
    "\n",
    "        zscore = np.mean(spikeDiff)/sdiffSD\n",
    "        if (zscore < 0.0):\n",
    "            pvalue = (t.cdf(zscore*np.sqrt(row['nTrials']), row['nTrials']))*2.0\n",
    "        else:\n",
    "            pvalue = (1.0 - t.cdf(zscore*np.sqrt(row['nTrials']), row['nTrials']))*2.0\n",
    "    else:\n",
    "        zscore = 0\n",
    "        pvalue = 1.0\n",
    "        \n",
    "    return zscore, pvalue, row['nTrials']\n",
    "\n",
    "def calc_zscore_category(catName):\n",
    "    global dfRelTime\n",
    "    \n",
    "    rows = []\n",
    "    # This loop finds all rows that match but there should only be one.\n",
    "    \n",
    "    nTotal = 0\n",
    "    for index, row in dfRelTime.iterrows():\n",
    "        if row['call_type'] == catName:\n",
    "            rows.append(row)\n",
    "            nTotal += row['nTrials']\n",
    "    if (nTotal == 0):\n",
    "        return 0.0, 1.0, nTotal\n",
    "    \n",
    "    spikeDiff = np.zeros(nTotal)\n",
    "    itot = 0\n",
    "    for row in rows:\n",
    "        for it in range(row['nTrials']):\n",
    "            spikeDiff[itot] = np.sum((row['spikeTimes'][it] >= 0) & (row['spikeTimes'][it] < 0.5)) - np.sum((row['spikeTimes'][it] >= -0.5) & (row['spikeTimes'][it] < 0)) \n",
    "            itot += 1\n",
    "            \n",
    "    # Calculate z-score and pvalue\n",
    "    if (nTotal > 1) :\n",
    "        sdiffSD = np.std(spikeDiff, ddof=1)\n",
    "        if sdiffSD == 0:\n",
    "            spikeDiff[0] += 1\n",
    "            sdiffSD = np.std(spikeDiff, ddof=1)\n",
    "\n",
    "        zscore = np.mean(spikeDiff)/sdiffSD\n",
    "        if (zscore < 0.0):\n",
    "            pvalue = (t.cdf(zscore*np.sqrt(row['nTrials']), row['nTrials']))*2.0\n",
    "        else:\n",
    "            pvalue = (1.0 - t.cdf(zscore*np.sqrt(row['nTrials']), row['nTrials']))*2.0\n",
    "    else:\n",
    "        zscore = 0\n",
    "        pvalue = 1.0\n",
    "        \n",
    "    return zscore, pvalue, nTotal\n",
    "\n",
    "\n",
    "def calc_zscore_all():  \n",
    "    global dfRelTime\n",
    "\n",
    "    # Loop through all stims and trials.\n",
    "    nTotal = 0\n",
    "    for index, row in dfRelTime.iterrows():\n",
    "        nTotal += row['nTrials']\n",
    "            \n",
    "    spikeDiff = np.zeros(nTotal)\n",
    "    itot = 0\n",
    "    for index, row in dfRelTime.iterrows():\n",
    "        for it in range(row['nTrials']):        \n",
    "            # Spike difference first 500 ms\n",
    "            spikeDiff[itot] = np.sum((row['spikeTimes'][it] >= 0) & (row['spikeTimes'][it] < 0.5)) - np.sum((row['spikeTimes'][it] >= -0.5) & (row['spikeTimes'][it] < 0)) \n",
    "            itot += 1\n",
    "\n",
    "    # Calculate z-score and pvalue\n",
    "    if (nTotal > 1) :\n",
    "        sdiffSD = np.std(spikeDiff, ddof=1)\n",
    "        if sdiffSD == 0:\n",
    "            spikeDiff[0] += 1   # Add a spike to generate SD\n",
    "            sdiffSD = np.std(spikeDiff, ddof=1)\n",
    "            \n",
    "        zscore = np.mean(spikeDiff)/sdiffSD\n",
    "        if (zscore < 0.0):\n",
    "            pvalue = (t.cdf(zscore*np.sqrt(nTotal), nTotal))*2.0\n",
    "        else:\n",
    "            pvalue = (1.0 - t.cdf(zscore*np.sqrt(nTotal), nTotal))*2.0\n",
    "    else: \n",
    "        zscore = 0\n",
    "        pvalue = 1.0\n",
    "        \n",
    "    return zscore, pvalue, nTotal\n",
    "\n",
    "    \n",
    "def load_playbackPkl(playbackPkl):\n",
    "    global unitInfo, dfRelTime\n",
    "                \n",
    "    # Load unitInfo and data frames \n",
    "    pklFile = playbackPkl\n",
    "    try:\n",
    "        fileIn = open(pklFile, 'rb')\n",
    "        try:\n",
    "            unitInfo = pk.load(fileIn)\n",
    "            dfAbsTime = pk.load(fileIn)\n",
    "            dfRelTime = pk.load(fileIn)\n",
    "            fileIn.close()\n",
    "        except:\n",
    "            print('Empty file: ', pklFile)\n",
    "    except OSError as err:\n",
    "        print(\"OS error: {0}\".format(err))\n",
    "\n",
    "    \n",
    "    return\n",
    "               \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through the data and make some raster plots for each stimulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loop again through the data to fill in PC values\n",
    "itKDE = 1000    # Number of points in the KDE for PCs\n",
    "tInt = 5.0      # This is for a correction for KDEs... (see Unit_readh5_files)\n",
    "good_Calls = ['Ag', 'Be', 'DC', 'Di', 'LT', 'Ne', 'So', 'Te', 'Th', 'Wh']\n",
    "nPC = 5\n",
    "\n",
    "for bird in birds:    \n",
    "    # Find sites\n",
    "    # Find pklfiles\n",
    "    pklfiles = glob.glob(os.path.join(rootPath,pklPath,bird, \"*.pkl\"))\n",
    "    kp = 'n'\n",
    "    print('----------------------'+bird+'-------------------------------')\n",
    "   \n",
    "    # Loop through sites\n",
    "    for playPkl in pklfiles:\n",
    "        load_playbackPkl(playPkl)\n",
    "        \n",
    "        # Get the site and unit name from the file name\n",
    "        site_unit = playPkl.split('/')[-1]\n",
    "        site_unit_split = site_unit.split('_')\n",
    "        site = site_unit_split[0]+ '_' + site_unit_split[1]\n",
    "        unit = site_unit.split(site)[1]\n",
    "        unit = unit[1:-4]\n",
    "            \n",
    "        # Select only single units.\n",
    "        if unitInfo['SpikeSNR'] < 5.0:\n",
    "            continue\n",
    "                \n",
    "        # Get a measure of auditory strength\n",
    "        zTot, pTot, nTot = calc_zscore_all()\n",
    "            \n",
    "        # Select only units that have significant auditory responses\n",
    "        if pTot > 0.01:\n",
    "            continue\n",
    "            \n",
    "        if zTot < 1:\n",
    "            continue\n",
    "                               \n",
    "        # Loop through call categories to get measure of call-type selectivity\n",
    "        calls = dfRelTime['call_type'].unique()\n",
    "        good_calls = [call for call in calls if call in good_Calls]\n",
    "        ncalls = len(good_calls)\n",
    "        callRendition = np.zeros(len(calls), dtype = int)\n",
    "            \n",
    "        if (ncalls == 0) :        # This happens if there is data for the other stims..\n",
    "            continue\n",
    "            \n",
    "        # Stuffing the arrays with the information                                     \n",
    "        for index, row in dfRelTime.iterrows():\n",
    "            \n",
    "            # Ignore stims that are not vocalizations\n",
    "            if row['call_type'] not in good_calls:\n",
    "                continue\n",
    "            if row['nTrials'] <5:\n",
    "                continue\n",
    "            if np.sum(np.concatenate(row['spikeTimes'])) == 0 :\n",
    "                continue\n",
    "                \n",
    "            callID = np.argwhere(row['call_type'] == calls)[0][0]\n",
    "            callRendition[callID] += 1\n",
    "\n",
    "            kdeNorm = row['spikeKDE'][0:itKDE]*tInt/row['nTrials']            \n",
    "            fsamp = 1/(row['tKDE'][1]-row['tKDE'][0])\n",
    "\n",
    "            PCSum = np.zeros((1, nPC))\n",
    "            PCtrial = np.zeros((row['nTrials'], nPC))\n",
    "            for it in range(row['nTrials']) :\n",
    "                PCtrial[it,:] = np.dot(pcKDE.components_[0:nPC,:], -pcKDE.mean_)   # This is how we remove the mean response before projecting into PC\n",
    "                for spikeTime in row['spikeTimes'][it]:                            \n",
    "                    if spikeTime < -0.5:\n",
    "                        continue\n",
    "                    iMin = np.argmin(np.abs(row['tKDE']-spikeTime))\n",
    "                    if iMin < 1000:\n",
    "                        PCtrial[it,:] += fsamp*pcKDE.components_[0:nPC,iMin]   # A single spike needs to be worth 1000.0 because our sampling rate of 1ms.\n",
    "                    else:\n",
    "                        break\n",
    "                PCSum += PCtrial[it,:]   \n",
    "                \n",
    "\n",
    "            kdeAVG = PCSum/row['nTrials']\n",
    "            \n",
    "            fig = plt.figure(figsize=(2,3), dpi=100)\n",
    "            ax = fig.subplots(2,1, gridspec_kw={'height_ratios': [3,1]}, sharex= True)\n",
    "\n",
    "            for it in range(row['nTrials']):\n",
    "                KDETrial = np.dot(PCtrial[it,:], pcKDE.components_[0:nPC,:]) + pcKDE.mean_\n",
    "                ax[1].plot(row['tKDE'][0:1000], KDETrial, color = '0.5', linewidth = 0.5)\n",
    "                for spikeTime in row['spikeTimes'][it]:\n",
    "                    if spikeTime < -0.5:\n",
    "                        continue\n",
    "                    ax[0].plot([spikeTime, spikeTime], [10*it, 10*it +5], 'k-', linewidth=0.5)\n",
    "\n",
    "            ax[0].set_title(site_unit + '_' + row['call_type'])\n",
    "            ax[0].set_xlim(-0.5, 1.5)\n",
    "            ax[0].set_axis_off()\n",
    "\n",
    "            # Reconstructed\n",
    "            ax[1].plot(row['tKDE'], row['spikeKDE']*tInt/row['nTrials'])\n",
    "\n",
    "            kdePC = pcKDE.transform(kdeNorm.reshape(1, -1))\n",
    "            KDERecon = np.dot(kdePC[0,0:nPC], pcKDE.components_[0:nPC,:]) + pcKDE.mean_\n",
    "            #ax[1].plot(row['tKDE'][0:1000], KDERecon, 'r')\n",
    "\n",
    "            KDERecon2 = np.dot(kdeAVG[0], pcKDE.components_[0:nPC,:]) + pcKDE.mean_\n",
    "            ax[1].plot(row['tKDE'][0:1000], KDERecon2, 'b')\n",
    "            ax[1].spines['top'].set_visible(False)\n",
    "            ax[1].spines['right'].set_visible(False)\n",
    "            plt.xlim(-0.5, 1.5)\n",
    "\n",
    "            plt.xlabel('Time (s)')\n",
    "            plt.show()\n",
    "            \n",
    "            kp = input('Type n (next), p(print and next), q(next bird), x(exit):')\n",
    "        \n",
    "            if kp == 'p':\n",
    "                fig.savefig('/Users/frederictheunissen/Desktop/'+bird + '_' + site_unit + '_' + row['call_type'] + str(callRendition[callID]) + '.eps')\n",
    "            elif (kp == 'q') or (kp =='x') :\n",
    "                break\n",
    "        \n",
    "        if (kp == 'q') or (kp == 'x'):\n",
    "            break\n",
    "        \n",
    "    if (kp == 'x'):\n",
    "        break\n",
    "        \n",
    "\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(callRendition[callID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callRendition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
