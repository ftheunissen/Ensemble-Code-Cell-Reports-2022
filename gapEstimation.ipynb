{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculates the duration of recordings and the gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "from scipy.special import erf\n",
    "import time\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "# Theunissen Lab Code\n",
    "import suss.io\n",
    "from analysis.playbacks.categories import create_stimulus_dataframe, inject_spikes, relative_spike_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "rootPathH = '/Users/frederictheunissen/Code/songephys/'\n",
    "dataPathH = 'data/birds/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data files \n",
    "inPathH = rootPathH+dataPathH+'summarySel.pkl'\n",
    "fileInH = open(inPathH,\"rb\")\n",
    "dfSummaryH = pk.load(fileInH)\n",
    "fileInH.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awake behaving data set:\n",
      "439 / 732 ( 59.97267759562842 ) auditory units\n",
      "62 / 439 ( 14.123006833712983 ) are inhibited by sound\n",
      "Awake behaving data set Single Units:\n",
      "292 / 732 ( 39.89071038251366 ) auditory single units\n",
      "46 / 292 ( 15.753424657534246 ) are inhibited by sound\n"
     ]
    }
   ],
   "source": [
    "# Number of auditory units\n",
    "\n",
    "nCellsH = dfSummaryH.shape[0]\n",
    "nAudH = sum(dfSummaryH['pAud']< 0.01)\n",
    "\n",
    "nInhH = sum((dfSummaryH['pAud']< 0.01) & (dfSummaryH['zAud']< 0.0))\n",
    "\n",
    "print(\"Awake behaving data set:\")\n",
    "print(nAudH,'/',nCellsH, '(', nAudH*100.0/nCellsH, ') auditory units')\n",
    "print(nInhH,'/',nAudH, '(', nInhH*100.0/nAudH, ') are inhibited by sound')\n",
    "\n",
    "\n",
    "\n",
    "# Repeat with single Units by SNR > 5\n",
    "\n",
    "nAudSUH = sum((dfSummaryH['pAud']< 0.01) & (dfSummaryH['snr'] >= 5.0))\n",
    "\n",
    "nInhSUH = sum((dfSummaryH['pAud']< 0.01) & (dfSummaryH['zAud']< 0.0) & (dfSummaryH['snr'] >= 5.0))\n",
    "\n",
    "print(\"Awake behaving data set Single Units:\")\n",
    "print(nAudSUH,'/',nCellsH, '(', nAudSUH*100.0/nCellsH, ') auditory single units')\n",
    "print(nInhSUH,'/',nAudSUH, '(', nInhSUH*100.0/nAudSUH, ') are inhibited by sound')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the results of Part 1 Runs that includes all neurons\n",
    "\n",
    "# Read the PC and Confusion matrices data base\n",
    "# Use the following data if NW\n",
    "#inPath = rootPath+dataPath+'HerminaDataBase1UnitPCNW.pkl'\n",
    "\n",
    "inPath = rootPathH+dataPathH+'HerminaDataBase1UnitPC.pkl'\n",
    "fileIn = open(inPath,\"rb\")\n",
    "unitNamesFull = pk.load(fileIn)\n",
    "confMatTot = pk.load(fileIn)\n",
    "pcc = pk.load(fileIn)\n",
    "fileIn.close()\n",
    "\n",
    "# These are the neurons that we will be keeping  Use 13 if NW 12 otherwise.\n",
    "indGood = np.argwhere(pcc > 12).flatten()\n",
    "nGood = indGood.shape[0]\n",
    "\n",
    "\n",
    "pccGood = pcc[indGood]\n",
    "unitNamesGood = [unitNamesFull[i] for i in indGood]\n",
    "\n",
    "indSort = np.flip(np.argsort(pccGood))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_playbackPkl(playPklPath, playbackPkl):\n",
    "    global unitInfo, dfAbsTime, dfRelTime\n",
    "                \n",
    "    # Load unitInfo and data frames - I don't need the times here\n",
    "    pklFile = playPklPath + playbackPkl\n",
    "    try:\n",
    "        fileIn = open(pklFile, 'rb')\n",
    "        try:\n",
    "            unitInfo = pk.load(fileIn)\n",
    "            #dfAbsTime = pk.load(fileIn)\n",
    "            #dfRelTime = pk.load(fileIn)\n",
    "            fileIn.close()\n",
    "        except:\n",
    "            print('Empty file: ', pklFile)\n",
    "    except OSError as err:\n",
    "        print(\"OS error: {0}\".format(err))\n",
    "\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_rate(bird, site, electrode, cluster, rateThresh, bandWidth):\n",
    "    \n",
    "    global X_anal, X_good, df\n",
    "    \n",
    "    if cluster == 'None':\n",
    "        print('Cluster is not defined')\n",
    "        return\n",
    "    # Load the raw spike data\n",
    "    # Set Paths\n",
    "    spikesPath = rootPathH + dataPathH + bird + '/sites/' + site + '/manually_curated/curated-e' + electrode + '.pkl'\n",
    "\n",
    "    # Load spike data and get a list of clusters\n",
    "    spike_file = suss.io.read_pickle(spikesPath)\n",
    "    \n",
    "    # Process the spikefile to get info\n",
    "    labeled_nodes_dict = dict(spike_file.labeled_nodes)\n",
    "    spikes = labeled_nodes_dict[cluster]\n",
    "    spikeTimes = spikes.flatten().times.reshape(-1,1)\n",
    "    \n",
    "    # Load the events file\n",
    "\n",
    "    eventsPath = rootPathH + dataPathH + bird + '/sites/' + site + '/vocal_periods.npy'\n",
    "    events = np.load(eventsPath, allow_pickle=True)[()]\n",
    "\n",
    "    # spikeWaveforms = spikes.flatten().waveforms\n",
    "    df = create_stimulus_dataframe(events[\"playback\"])\n",
    "    df = inject_spikes(df, spikeTimes.flatten(), t_buffer=10)\n",
    "    \n",
    "    \n",
    "    # Generate a continuous spike rate with a wide filter\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=bandWidth).fit(spikeTimes)\n",
    "\n",
    "    tStart = np.fix(spikeTimes[0]-2)\n",
    "    tEnd = np.fix(spikeTimes[-1]+2)\n",
    "    npts = int(tEnd-tStart)+1\n",
    "\n",
    "    X_anal = np.linspace(np.reshape(tStart, (1,)), np.reshape(tEnd, (1,)), npts)\n",
    "\n",
    "    spikeDens = np.exp(kde.score_samples(X_anal))\n",
    "    spikeDens = spikeDens*len(spikeTimes)/sum(spikeDens) \n",
    "\n",
    "    # Put a threshold for rate above rateThres in spikes/s\n",
    "    X_good = spikeDens > rateThresh\n",
    "    timeGood = np.array(X_good, dtype = 'int16')*rateThresh\n",
    "    \n",
    "    # Find maximum and minum times in events used in analysis\n",
    "    tBeg = np.min(df.loc[df['call_type'] != None]['start_time'])\n",
    "    tEnd = np.max(df.loc[df['call_type'] != None]['stop_time'])\n",
    "    \n",
    "    # calculate recording times and gap times\n",
    "    tgaps = []\n",
    "    trecs = []\n",
    "\n",
    "    tbeggap = 0\n",
    "    tbegrec = 0\n",
    "    prev = False\n",
    "    first = True\n",
    "    for i, val in enumerate(X_good):\n",
    "        if (X_anal[i] < tBeg):\n",
    "            tbeggap = i+1\n",
    "            tbegrec = i+1\n",
    "            continue\n",
    "        if val & ~prev:   # Step on\n",
    "            prev = True\n",
    "            dt = i - tbeggap\n",
    "            tbegrec = i\n",
    "            if not first:\n",
    "               tgaps.append(dt)\n",
    "            first = False\n",
    "        elif ~val & prev: # Step off\n",
    "            prev = False\n",
    "            dt = i - tbegrec\n",
    "            trecs.append(dt)\n",
    "            tbeggap = i\n",
    "        if (X_anal[i] >= tEnd):\n",
    "            break\n",
    "\n",
    "    i +=1\n",
    "    if prev:\n",
    "       trecs.append(i-tbegrec)\n",
    "    # else :   last gap does not count because we might have lost unit\n",
    "    #   tgaps.append(i-tbeggap)\n",
    "    \n",
    "    return trecs, tgaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "birds = []\n",
    "sites = []\n",
    "pklFiles = []\n",
    "electrodes = []\n",
    "clusters = []\n",
    "rateThs = []\n",
    "kdeBws = []\n",
    "\n",
    "\n",
    "# Getting the information for the 100 discriminating units used in the decoder\n",
    "for ind in indSort:\n",
    "    bird = unitNamesGood[ind][0:4]\n",
    "    site = unitNamesGood[ind].split('good')[0][0:-1]\n",
    "    pklFile = 'good' + unitNamesGood[ind].split('good')[1]\n",
    "    electrode = pklFile.split('-')[1][1:]\n",
    "    cluster = (pklFile.split('-')[2][1:]).split('.')[0]\n",
    "    playPklPath = rootPathH + dataPathH + bird + '/sites/' + site + '/PlaybackPkl/'\n",
    "    \n",
    "    # load the unitinfo data\n",
    "    load_playbackPkl(playPklPath, pklFile)\n",
    "    \n",
    "    # Store it\n",
    "    birds.append(bird)\n",
    "    sites.append(site)\n",
    "    pklFiles.append(pklFile)\n",
    "    electrodes.append(electrode)\n",
    "    clusters.append(cluster)\n",
    "    rateThs.append(unitInfo['RateThreshold'])\n",
    "    kdeBws.append(unitInfo['KDE_BW'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this data\n",
    "outPathH = rootPathH+dataPathH+'goodUnitsThInfo.pkl'\n",
    "fileoutH = open(outPathH,\"wb\")    \n",
    " \n",
    "unitInfoH = { 'birds': birds, 'sites' : sites,\n",
    "              'pklFiles': pklFiles, 'electrodes' : electrodes,\n",
    "              'clusters' : clusters, 'rateThs': rateThs, 'kdeBws': kdeBws} \n",
    "\n",
    "pk.dump(unitInfoH, fileoutH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read this data\n",
    "inPathH = rootPathH+dataPathH+'goodUnitsThInfo.pkl'\n",
    "fileinH = open(inPathH,\"rb\") \n",
    "\n",
    "unitInfoH = pk.load(fileinH)\n",
    "\n",
    "birds = unitInfoH['birds']\n",
    "sites = unitInfoH['sites']\n",
    "electrodes = unitInfoH['electrodes']\n",
    "clusters= unitInfoH['clusters']\n",
    "rateThs = unitInfoH['rateThs']\n",
    "kdeBws = unitInfoH['kdeBws']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through all units\n",
    "\n",
    "unitRecs = []\n",
    "unitGaps = []\n",
    "unitRecTot = []\n",
    "unitGapTot = []\n",
    "unitGapN = []\n",
    "unitGapMean = []\n",
    "unitGapMax = []\n",
    "unitGapMin = []\n",
    "for i, bird in enumerate(birds):\n",
    "    trecs, tgaps = good_rate(bird, sites[i], electrodes[i], int(clusters[i]), rateThs[i], kdeBws[i])\n",
    "    \n",
    "    unitRecs.append(trecs)\n",
    "    unitGaps.append(tgaps)\n",
    "    unitRecTot.append(np.sum(trecs)) \n",
    "    unitGapTot.append(np.sum(tgaps))\n",
    "    unitGapN.append(len(tgaps))\n",
    "    if (len(tgaps)):    \n",
    "        unitGapMean.append(np.mean(tgaps))\n",
    "        unitGapMax.append(np.max(tgaps))\n",
    "        unitGapMin.append(np.min(tgaps))\n",
    "    else:\n",
    "        unitGapMean.append(0.0)\n",
    "        unitGapMax.append(0.0)\n",
    "        unitGapMin.append(0.0)\n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Recording Time:\n",
      "\tMean: 02:45:58\n",
      "\tStd: 01:11:04\n",
      "\tMin: 00:16:21\n",
      "\tMax: 06:30:11\n",
      "Number of gaps:\n",
      "\tMean: 10.04\n",
      "\tStd: 8.176698600290951\n",
      "\tMin: 0\n",
      "\tMax: 39\n",
      "Gap Length:\n",
      "\tMean: 00:06:44\n",
      "\tStd: 00:10:16\n",
      "\tMin: 00:00:01\n",
      "\tMax: 02:26:43\n",
      "Percent time of clean recording:\n",
      "\tMean: 63.821507739715564\n",
      "\tMin: 16.603648738065978\n",
      "\tMax: 100.0\n"
     ]
    }
   ],
   "source": [
    "# Print some results\n",
    "\n",
    "print('Total Recording Time:')\n",
    "print('\\tMean:', time.strftime('%H:%M:%S', time.gmtime(np.mean(np.array(unitGapTot)+np.array(unitRecTot)))))\n",
    "print('\\tStd:', time.strftime('%H:%M:%S', time.gmtime(np.std(np.array(unitGapTot)+np.array(unitRecTot)))))\n",
    "print('\\tMin:', time.strftime('%H:%M:%S', time.gmtime(np.min(np.array(unitGapTot)+np.array(unitRecTot)))))\n",
    "print('\\tMax:', time.strftime('%H:%M:%S', time.gmtime(np.max(np.array(unitGapTot)+np.array(unitRecTot)))))\n",
    "\n",
    "print('Number of gaps:')\n",
    "print('\\tMean:', np.mean(np.array(unitGapN)))\n",
    "print('\\tStd:', np.std(np.array(unitGapN)))\n",
    "print('\\tMin:', np.min(np.array(unitGapN)))\n",
    "print('\\tMax:', np.max(np.array(unitGapN)))\n",
    "\n",
    "print('Gap Length:')\n",
    "print('\\tMean:', time.strftime('%H:%M:%S', time.gmtime(np.mean(np.concatenate(unitGaps).flatten()))))\n",
    "print('\\tStd:', time.strftime('%H:%M:%S', time.gmtime(np.std(np.concatenate(unitGaps).flatten()))))\n",
    "print('\\tMin:', time.strftime('%H:%M:%S', time.gmtime(np.min(np.concatenate(unitGaps).flatten()))))\n",
    "print('\\tMax:', time.strftime('%H:%M:%S', time.gmtime(np.max(np.concatenate(unitGaps).flatten()))))\n",
    "\n",
    "print('Percent time of clean recording:')\n",
    "print('\\tMean:', np.mean(np.array(unitRecTot)/(np.array(unitGapTot)+np.array(unitRecTot))*100))\n",
    "print('\\tMin:', np.min(np.array(unitRecTot)/(np.array(unitGapTot)+np.array(unitRecTot))*100))\n",
    "print('\\tMax:', np.max(np.array(unitRecTot)/(np.array(unitGapTot)+np.array(unitRecTot))*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
